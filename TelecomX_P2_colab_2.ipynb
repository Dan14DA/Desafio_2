{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f726b9af",
   "metadata": {},
   "source": [
    "# Telecom X — Parte 2 · Predicción de Churn (Versión B)\n",
    "\n",
    "**Diferencias**: feature engineering extra, validación repetida (5×2), calibración seleccionada por Brier, y doble criterio de umbral de negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dependencias (solo Colab) ===\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    !pip -q install imbalanced-learn >/dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports y setup ===\n",
    "import os, json, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_recall_curve, roc_curve,\n",
    "                             confusion_matrix, classification_report, brier_score_loss)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 17\n",
    "np.random.seed(RANDOM_STATE)\n",
    "USE_BALANCING = False\n",
    "BALANCING_METHOD = 'ros'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Parámetros ===\n",
    "CSV_PATH = '/content/df_limpo.csv'\n",
    "VALUE_RETAIN = 120.0\n",
    "COST_CONTACT = 4.0\n",
    "TOP_N = 300\n",
    "os.makedirs('/content/reports', exist_ok=True)\n",
    "os.makedirs('/content/data/interim', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f71e2",
   "metadata": {},
   "source": [
    "## 1) Carga y feature engineering (versión B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f'No se encontró df_limpo.csv en {CSV_PATH}')\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Shape df:', df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "assert 'Churn' in df.columns, \"El CSV tratado debe incluir la columna 'Churn'\"\n",
    "y_raw = df['Churn'].astype('string').str.strip().str.lower()\n",
    "mask = y_raw.isin(['yes','no'])\n",
    "dfm = df.loc[mask].copy()\n",
    "dfm['Churn_bin'] = y_raw.loc[mask].map({'yes':1,'no':0}).astype(int)\n",
    "\n",
    "# --- Feature engineering extra ---\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(str(x).strip())\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "monthly = None; total = None; tenure = None\n",
    "for c in dfm.columns:\n",
    "    lc = c.lower()\n",
    "    if 'monthly' in lc and 'charge' in lc: monthly = c\n",
    "    if 'total' in lc and 'charge' in lc: total = c\n",
    "    if 'tenure' in lc: tenure = c\n",
    "\n",
    "if total is not None:\n",
    "    dfm['_TotalCharges_num'] = dfm[total].apply(safe_float)\n",
    "if monthly is not None:\n",
    "    dfm['_MonthlyCharges_num'] = pd.to_numeric(dfm[monthly], errors='coerce')\n",
    "if tenure is not None:\n",
    "    dfm['_tenure_num'] = pd.to_numeric(dfm[tenure], errors='coerce')\n",
    "\n",
    "if 'internet.InternetService' in dfm.columns:\n",
    "    dfm['has_fiber'] = dfm['internet.InternetService'].astype('string').str.contains('fiber', case=False, na=False).astype(int)\n",
    "else:\n",
    "    dfm['has_fiber'] = 0\n",
    "\n",
    "if '_tenure_num' in dfm.columns:\n",
    "    dfm['tenure_bin'] = pd.cut(dfm['_tenure_num'], bins=[-1,1,3,6,12,24,48,72,1e9],\n",
    "                               labels=['0-1','2-3','4-6','7-12','13-24','25-48','49-72','72+'])\n",
    "else:\n",
    "    dfm['tenure_bin'] = 'unk'\n",
    "\n",
    "if all(c in dfm.columns for c in ['_TotalCharges_num','_MonthlyCharges_num','_tenure_num']):\n",
    "    dfm['charges_ratio'] = dfm['_TotalCharges_num'] / (dfm['_MonthlyCharges_num'] * (dfm['_tenure_num']+1))\n",
    "else:\n",
    "    dfm['charges_ratio'] = np.nan\n",
    "\n",
    "X = dfm.drop(columns=['Churn','Churn_bin','customerID'], errors='ignore')\n",
    "y = dfm['Churn_bin'].to_numpy()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print('num_cols:', len(num_cols), '| cat_cols:', len(cat_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a20a7e",
   "metadata": {},
   "source": [
    "## 2) Preprocesamiento y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "\n",
    "transformers = []\n",
    "if len(num_cols)>0: transformers.append(('num', num_pipe, num_cols))\n",
    "if len(cat_cols)>0: transformers.append(('cat', cat_pipe, cat_cols))\n",
    "pre = ColumnTransformer(transformers)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print('Train/Test:', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ab20b",
   "metadata": {},
   "source": [
    "## 3) Selección de variables (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ed0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = pre.fit_transform(X)\n",
    "mi = mutual_info_classif(Xt, y, discrete_features=False, random_state=RANDOM_STATE)\n",
    "def get_feature_names(pre, num_cols, cat_cols):\n",
    "    out = []\n",
    "    if 'num' in pre.named_transformers_ and pre.named_transformers_['num'] is not None:\n",
    "        out.extend(num_cols)\n",
    "    if 'cat' in pre.named_transformers_ and pre.named_transformers_['cat'] is not None:\n",
    "        oh = pre.named_transformers_['cat'].named_steps['onehot']\n",
    "        out.extend(oh.get_feature_names_out(cat_cols).tolist())\n",
    "    return out\n",
    "feat_names = get_feature_names(pre, num_cols, cat_cols)\n",
    "pairs = sorted(zip(feat_names, mi), key=lambda x: x[1], reverse=True)[:25]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh([n for n,_ in pairs[::-1]], [v for _,v in pairs[::-1]])\n",
    "plt.title('Top 25 — Información Mutua'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b128d",
   "metadata": {},
   "source": [
    "## 4) Modelos + GridSearch (PR-AUC) con validación repetida (5×2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=RANDOM_STATE)\n",
    "models = {\n",
    "  'logreg': (LogisticRegression(max_iter=2000, class_weight='balanced'),\n",
    "             {'model__C':[0.1,1,5,10]}),\n",
    "  'rf': (RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1, class_weight='balanced'),\n",
    "         {'model__max_depth':[None,10,16], 'model__min_samples_leaf':[1,3,6]}),\n",
    "  'hgb': (HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "          {'model__learning_rate':[0.05,0.1], 'model__max_depth':[None,10,14]})\n",
    "}\n",
    "\n",
    "best_est, best_name, best_score = None, None, -np.inf\n",
    "scores = {}\n",
    "for name, (est, grid) in models.items():\n",
    "    pipe = Pipeline([('pre', pre), ('model', est)])\n",
    "    gs = GridSearchCV(pipe, grid, scoring='average_precision', cv=cv, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    scores[name] = gs.best_score_\n",
    "    if gs.best_score_ > best_score:\n",
    "        best_est, best_name, best_score = gs.best_estimator_, name, gs.best_score_\n",
    "print('PR-AUC (CV repetida):')\n",
    "for k,v in scores.items():\n",
    "    print(f'{k:8s} -> {v:.4f}')\n",
    "print(f'Mejor: {best_name} ({best_score:.4f})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db46e38",
   "metadata": {},
   "source": [
    "## 5) Calibración por Brier (isotónica vs Platt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_fitted = best_est.named_steps['pre'].fit(X_train, y_train)\n",
    "Xtr = pre_fitted.transform(X_train)\n",
    "Xte = pre_fitted.transform(X_test)\n",
    "base = best_est.named_steps['model']\n",
    "\n",
    "def fit_calibrated(base, Xtr, ytr, Xte, yte):\n",
    "    out = {}\n",
    "    try:\n",
    "        iso = CalibratedClassifierCV(base, method='isotonic', cv=3).fit(Xtr, ytr)\n",
    "        p_iso = iso.predict_proba(Xte)[:,1]; out['isotonic'] = (p_iso, brier_score_loss(yte, p_iso))\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        pl = CalibratedClassifierCV(base, method='sigmoid', cv=3).fit(Xtr, ytr)\n",
    "        p_pl = pl.predict_proba(Xte)[:,1]; out['platt'] = (p_pl, brier_score_loss(yte, p_pl))\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not out:\n",
    "        if hasattr(base, 'predict_proba'):\n",
    "            p = base.fit(Xtr, ytr).predict_proba(Xte)[:,1]\n",
    "        else:\n",
    "            s = base.fit(Xtr, ytr).decision_function(Xte)\n",
    "            s = (s - s.min())/(s.max()-s.min()+1e-9)\n",
    "            p = s\n",
    "        return p, 'none', brier_score_loss(yte, p)\n",
    "    # elegir por menor Brier\n",
    "    m, (pp, bs) = min(out.items(), key=lambda kv: kv[1][1])\n",
    "    return pp, m, bs\n",
    "\n",
    "y_score, cal_used, brier = fit_calibrated(base, Xtr, y_train, Xte, y_test)\n",
    "roc = roc_auc_score(y_test, y_score)\n",
    "pr  = average_precision_score(y_test, y_score)\n",
    "print(f'Calibración: {cal_used} | Brier: {brier:.4f} | ROC-AUC: {roc:.4f} | PR-AUC: {pr:.4f}')\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_score)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "plt.figure(figsize=(6,4)); plt.plot(rec, prec); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('PR curve'); plt.show()\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC curve'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513246d",
   "metadata": {},
   "source": [
    "## 6) Umbral de negocio: máxima ganancia y no-pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_profit(y_true, p, thr, value=VALUE_RETAIN, cost=COST_CONTACT):\n",
    "    y_pred = (p>=thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp*value - (tp+fp)*cost\n",
    "\n",
    "thr_grid = np.linspace(0.005, 0.5, 200)\n",
    "profits = np.array([business_profit(y_test, y_score, t) for t in thr_grid])\n",
    "idx = int(np.argmax(profits)); thr_best = float(thr_grid[idx]); profit_best = float(profits[idx])\n",
    "thr_safe = float(thr_grid[np.argmax(profits>=0)]) if np.any(profits>=0) else float(thr_best)\n",
    "print(f'Threshold óptimo (ganancia): {thr_best:.3f} | Ganancia: {profit_best:.2f}')\n",
    "print(f'Threshold no-pérdida: {thr_safe:.3f}')\n",
    "plt.figure(figsize=(6,4)); plt.plot(thr_grid, profits); plt.axvline(thr_best, ls='--'); plt.axvline(thr_safe, ls=':');\n",
    "plt.xlabel('Threshold'); plt.ylabel('Profit'); plt.title('Curva de ganancia'); plt.show()\n",
    "\n",
    "for thr in [thr_best, thr_safe]:\n",
    "    print(f'--- Umbral {thr:.3f} ---')\n",
    "    y_pred = (y_score>=thr).astype(int)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87b9a0",
   "metadata": {},
   "source": [
    "## 7) Artefactos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "  'best_model': best_name,\n",
    "  'cv_best_pr_auc': float(best_score),\n",
    "  'test_roc_auc': float(roc),\n",
    "  'test_pr_auc': float(pr),\n",
    "  'brier_score': float(brier),\n",
    "  'calibration': cal_used,\n",
    "  'thr_best': float(thr_best),\n",
    "  'thr_safe': float(thr_safe),\n",
    "  'profit_best': float(profit_best),\n",
    "  'value_retain': float(VALUE_RETAIN),\n",
    "  'cost_contact': float(COST_CONTACT)\n",
    "}\n",
    "with open('/content/reports/metrics_p2_v2.json','w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print('Guardado metrics_p2_v2.json')\n",
    "\n",
    "lines = []\n",
    "lines.append('# Informe de Resultados — Telecom X · Parte 2 (Versión B)')\n",
    "lines.append('')\n",
    "lines.append('## 1. Datos y validación')\n",
    "lines.append(f'- Filas: {df.shape[0]} | Columnas: {df.shape[1]}')\n",
    "lines.append(f'- Split 80/20 estratificado | CV repetida 5×2 (PR-AUC)')\n",
    "lines.append('')\n",
    "lines.append('## 2. Modelo y calibración')\n",
    "lines.append(f'- Mejor por CV (PR-AUC): **{best_name}** → {best_score:.4f}')\n",
    "lines.append(f'- Test: ROC-AUC={roc:.4f} | PR-AUC={pr:.4f} | Brier={brier:.4f} | cal={cal_used}')\n",
    "lines.append('')\n",
    "lines.append('## 3. Umbral de negocio')\n",
    "lines.append(f'- Máxima ganancia: thr={thr_best:.3f} → {profit_best:.2f} (VALUE_RETAIN={VALUE_RETAIN}, COST_CONTACT={COST_CONTACT})')\n",
    "lines.append(f'- No-pérdida: thr={thr_safe:.3f}')\n",
    "with open('/content/reports/README_REPORT_P2_v2.md','w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(lines))\n",
    "print('Guardado README_REPORT_P2_v2.md')\n",
    "\n",
    "salida = dfm.loc[X_test.index].copy()\n",
    "salida['churn_score'] = y_score\n",
    "salida['flag_churn_risk'] = (y_score >= thr_best).astype(int)\n",
    "topN = salida.sort_values('churn_score', ascending=False).head(TOP_N)\n",
    "top_path = '/content/reports/clientes_en_riesgo_topN_p2_v2.csv'\n",
    "topN.to_csv(top_path, index=False)\n",
    "print('Exportado', top_path)\n",
    "topN.head(5)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
